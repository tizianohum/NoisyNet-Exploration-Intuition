env:
  name: MiniGrid-Empty-5x5-v0  # Gym environment name

seed: 0

agent:
  buffer_capacity:    25000    # max replay buffer size
  batch_size:         256       # minibatch size
  learning_rate:      0.0001    # maps to DQNAgentâ€™s lr
  gamma:              0.6
  epsilon_start:      1.0
  epsilon_final:      0.05
  epsilon_decay:      10000
  target_update_freq: 1000
  use_noisy_net:      True     # Set to True to use NoisyNet exploration
  minReward:          0
  maxReward:          1

train:
  num_frames:     15000   # total env steps
  eval_interval:  1000    # print avg reward every this many episodes